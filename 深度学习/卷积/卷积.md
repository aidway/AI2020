# 卷积

## 1*1卷积

- 1×1卷积可以看作是通道维上的全连接

![一乘一卷积](E:\git\AI2020\深度学习\卷积\imgs\一乘一卷积.png)

## 单通道卷积

![单通道卷积2](E:\git\AI2020\深度学习\卷积\imgs\单通道卷积2.png)



![单通道卷积](E:\git\AI2020\深度学习\卷积\imgs\单通道卷积.png)

<center>figure 1-1</center>



![动态单通道卷积](E:\git\AI2020\深度学习\卷积\imgs\动态单通道卷积.gif)



## 多通道卷积

![多通道卷积](E:\git\AI2020\深度学习\卷积\imgs\多通道卷积.png)

<center>figure 1-2</center>

​	多通道卷积如上图所示，图中输入图像尺寸为6×6，通道数为3。卷积核有2个，每个尺寸为3×3，通道数为3（与输入图像通道数一致）。卷积时，仍是以滑动窗口的形式，从左至右，从上至下，3个通道的对应位置相乘求和，输出结果为2张4×4的特征图。一般地，当输入为m×n×c时，每个卷积核为k×k×c，即每个卷积核的通道数应与输入的通道数相同（因为多通道需同时卷积），输出的特征图数量与卷积核数量一致。





![动态多通道卷积](E:\git\AI2020\深度学习\卷积\imgs\动态多通道卷积.gif)

![多通道卷积2](E:\git\AI2020\深度学习\卷积\imgs\多通道卷积2.png)



## 卷积核的意义

1. **从函数（或者说映射、变换）的角度理解。** 卷积过程是在图像每个位置进行线性变换映射成新值的过程，将卷积核看成权重，若拉成向量记为w，图像对应位置的像素拉成向量记为x，则该位置卷积结果为y=w′x+by=w′x+b，即向量内积+偏置，将x变换为y。**从这个角度看，多层卷积是在进行逐层映射，整体构成一个复杂函数，训练过程是在学习每个局部映射所需的权重，训练过程可以看成是函数拟合的过程。**
2. **从模版匹配的角度理解。**     **卷积核定义了某种模式，卷积（相关）运算是在计算每个位置与该模式的相似程度，或者说每个位置具有该模式的分量有多少，当前位置与该模式越像，响应越强**。





# 池化

- 池化层没有模型参数（池化层直接对窗口内的元素求最大值或平均值，并没有模型参数参与计算）
- 池化层的输入和输出具有相同的通道数

![动态单通道池化](E:\git\AI2020\深度学习\卷积\imgs\动态单通道池化.gif)



## 最大池化

![max_pool](E:\git\AI2020\深度学习\卷积\imgs\max_pool.png)

## 平均池化

# CNN特点

1. 局部连接

   每个神经元仅与输入神经元的一块区域连接，这块局部区域称作感受野（receptive field）。

   ![局部感知](E:\git\AI2020\深度学习\卷积\imgs\局部感知.png)

2. 参数共享

   计算同一个深度切片的神经元时采用的滤波器是共享的。

# 重要概念

1. 感受野：特征图中的cell对应到原图输入的响应大小。
2. 两个连续的3×3卷积核的感受野与一个5×5卷积核的感受野相同

# 参考

1. [卷积神经网络之卷积计算、作用与思想](https://www.cnblogs.com/shine-lee/p/9932226.html)



# 问题

1. 为什么卷积核大小常用奇数？

2. 假如用全连接层处理一张256×256的彩色（RGB）图像，输出包含1000个神经元，在使用偏置的情况下，参数数量是多少？

   解答：

   图像展平后长度为3×256×256

   权重参数和偏置参数的数量：3×256×256×1000+1000=196609000

3. 假如用卷积层处理一张256×256的彩色（RGB）图像，卷积核的高宽是3×3，输出包含10个通道，在使用偏置的情况下，这个卷积层共有多少个参数？

   解答：

   输入通道数是3，输出通道数是10，所以参数数量是10×3×3×3+10=280

4. 